variables:
  UPSTREAM_GIT_URL: 'https://github.com/jpillora/chisel.git'
  UPSTREAM_DOCKERFILE_PATH: '.'

stages:
  - run-backups
  - docker-get-version
  - docker-build
  - docker-push

include:
  - project: applications/tooling
    ref: main
    file: 'gitlab-ci-includes/build-oci-image.yml'

run-backups-ph3-local:
  stage: run-backups
  tags:
    - lu-ghanima-local
  image:
    name: cr.ghanima.net/applications/sanoid/syncoid-pull-server:latest
    entrypoint: [""]
  variables:
    SSH_REMOTE_HOST: ph3.local
    SSH_PORT: 10022
    SSH_PRIVKEY: $PH3LOCAL_SSH_PRIVKEY
    SSH_KNOWN_HOSTS: $PH3LOCAL_SSH_KNOWN_HOSTS
    SOURCE_DATASET: SSD1/VMs/machines/portainer1.ghanima.net
    DESTINATION_DATASET: SLAB/Backups/Syncoid/ph3.local/portainer1.ghanima.net
  artifacts:
    paths:
      - backup_result.json
  rules:
    - if: $RUNBACKUPS
  script: |
    SSH_REMOTE_HOST="${SSH_REMOTE_HOST:-"ph3.local"}"
    SSH_USERNAME="${SSH_USERNAME:-"syncoid"}"
    SSH_PORT="${SSH_PORT:-10022}"
    SSH_PRIVKEY="${SSH_PRIVKEY}"
    SSH_KNOWN_HOSTS="${SSH_KNOWN_HOSTS}"
    SOURCE_DATASET="${SOURCE_DATASET}"
    DESTINATION_DATASET="${DESTINATION_DATASET}"
    MINIMUM_COUNT_OF_BACKUPS_TO_KEEP="${MINIMUM_COUNT_OF_BACKUPS_TO_KEEP:-14}"
    MINIMUM_AGE_OF_BACKUP_TO_DELETE="${MINIMUM_AGE_OF_BACKUP_TO_DELETE:-1209600}" # 14 days
    start_time=$(date +%s)

    # Don't assume that these normal environment variables are set.
    if [ "${USER}" == "" ]; then
      export USER=$(id -un)
    fi
    if [ "${HOME}" == "" ]; then
      export HOME=$(getent passwd "${USER}" | awk 'BEGIN{FS=":"}{print $6}')
    fi

    RED='\033[1;31m'
    GREEN='\033[1;32m'
    YELLOW='\033[1;33m'
    GRAY='\033[1;90m'
    NC='\033[0m' # No Color
    export

    function verbose() {
      printf '%b\n' "${YELLOW}${1}${NC}"
    }

    function debug() {
      printf '%b\n' "${GRAY}${1}${NC}"
    }

    function info() {
      printf '%b\n' "${GREEN}${1}${NC}"
    }

    function error() {
      printf '%b\n' "${RED}${1}${NC}"
    }

    # Create and populate a ~/.ssh/config file
    # TODO: This need to be expandable to multiple remote targets
    mkdir -p "${HOME}/.ssh"
    chmod 700 "${HOME}/.ssh"
    cat >${HOME}/.ssh/config <<-EOF
    Host ${SSH_REMOTE_HOST}
      HostName      chisel
      User          ${SSH_USERNAME}
      Port          ${SSH_PORT}
      IdentityFile  ${HOME}/.ssh/${SSH_USERNAME}@${SSH_REMOTE_HOST}
    EOF

    #printf '%b' $(printf '%b' "${SSH_PRIVKEY}") >${HOME}/.ssh/${SSH_USERNAME}@${SSH_REMOTE_HOST}
    printf '%b' "${SSH_PRIVKEY}" >${HOME}/.ssh/${SSH_USERNAME}@${SSH_REMOTE_HOST}
    chmod 600 "${HOME}/.ssh/${SSH_USERNAME}@${SSH_REMOTE_HOST}"
    printf '%b' "${SSH_KNOWN_HOSTS}" >${HOME}/.ssh/known_hosts
    chmod 600 ${HOME}/.ssh/known_hosts
    cat ${HOME}/.ssh/known_hosts

    syncoid_log="/tmp/${SSH_REMOTE_HOST}.log"
    syncoid --debug --dumpsnaps --create-bookmark --no-sync-snap --no-privilege-elevation --sendoptions="w" "${SSH_USERNAME}@${SSH_REMOTE_HOST}:${SOURCE_DATASET}" "${DESTINATION_DATASET}" | tee "${syncoid_log}"

    # Cleanup oldest snapshots on the destination
    all_snapshots=$(zfs list -H -t snapshot -o name -d 1 "${DESTINATION_DATASET}")
    all_snapshots_count=$(printf '%s' "${all_snapshots}" | wc -l)
    if [ $all_snapshots_count -gt $MINIMUM_COUNT_OF_BACKUPS_TO_KEEP ]; then
      echo "More than ${MINIMUM_COUNT_OF_BACKUPS_TO_KEEP} snapshots exist on the destination dataset.  Looking for candidates to prune."
      while read object_name; do
        object_date=$(date +%s -d "$(printf '%s' "${object_name}" | sed 's/_[^0-9].*$//g' | awk 'BEGIN{FS="_"}{print $(NF-1)" "$NF}')")
        echo "Snapshot: ${object_name} - ${object_date}"
      done < <(printf '%s' "${all_snapshots}")

      #old_objects=$(printf '%s' "${all_remote_objects}" | jq "[ .[] | select((.UnixTime | tonumber) < $minimum_timestamp_of_backup) ]")
      #old_objects_count=$(printf '%s' "${old_objects}" | jq "length")
      #for (( i=0; i<$old_objects_count; i++ )) do
      #  object_name=$(printf '%s' "${old_objects}" | jq -r ".[$i].Name")
      #  object_path=$(printf '%s' "${old_objects}" | jq -r ".[$i].Path")
      #  object_date=$(printf '%s' "${old_objects}" | jq -r ".[$i].UnixTime")
      #  echo "Backup '${object_name}', created $(date -d "@${object_date}") is more than ${MINIMUM_AGE_OF_BACKUP_TO_DELETE} seconds old.  It can be pruned." | info
      #  echo "rclone rm \"wasabi:${S3_BUCKET}/${object_path}\"" | debug
      #done
    fi

    send_size=$(cat "${syncoid_log}" | grep '^DEBUG: sendsize = ' | awk 'BEGIN{FS=" = ";total=0}{total=total+$2}END{print total}')
    result_json=$(echo "{}" | jq ".sendsize=${send_size}")
    resumed=$(cat "${syncoid_log}" | grep -c "^Resuming interrupted zfs send/receive")
    result_json=$(printf '%s' "${result_json}" | jq ".resumed=${resumed}")
    duration=$(( $(date +%s) - $start_time ))
    result_json=$(printf '%s' "${result_json}" | jq ".resumed=${duration}")
    error_msg=$(cat "${syncoid_log}" | grep -B 1 "CRITICAL ERROR:")
    result_json=$(printf '%s' "${result_json}" | jq ".resumed=${error_msg}")
    error_count=$(cat "${syncoid_log}" | grep -c "CRITICAL ERROR:")
    result_json=$(printf '%s' "${result_json}" | jq ".resumed=${error_count}")
    error_out_of_space=$(cat "${syncoid_log}" | grep -c "out of space")
    result_json=$(printf '%s' "${result_json}" | jq ".commonIssues={destinationOutOfSpace:${error_out_of_space}}")
    error_connection_refused=$((cat "${syncoid_log}" | grep -c 'ssh: connect to host chisel port.*Connection refused')
    result_json=$(printf '%s' "${result_json}" | jq ".commonIssues={connectionToSourceRefused:${error_connection_refused}}")

    printf '%s' "${result_json}" | jq -C
    printf '%s' "${result_json}" > backup_result.json

docker-chisel-image-get-version:
  stage: docker-get-version
  extends: .docker:get-version
  image: bash:latest
  variables:
    UPSTREAM_GIT_URL: 'https://github.com/jpillora/chisel.git'
    UPSTREAM_DOCKERFILE_PATH: '.'
    IMAGE_NAME: 'chisel'
  rules:
    - if: $DOCKERIMAGEUPDATE
  script:
    - |
      OPWD=$(pwd)
      IMAGE_NAME="${IMAGE_NAME:-$(basename "${CI_REGISTRY_IMAGE}")}"

      apk add git || apt install git
      git clone ${UPSTREAM_GIT_URL} "${OPWD}/build-tmp"
      cd "${OPWD}/build-tmp"
      latest_tag=$(git describe --abbrev=0 --tags)
      cd "${OPWD}"
      echo "VERSION_TAGS[latest]=${latest_tag}" | tee -a ${IMAGE_NAME}-VERSION_TAGS
      cat ${IMAGE_NAME}-VERSION_TAGS
      readlink -f "${IMAGE_NAME}-VERSION_TAGS"

docker-chisel-image-build:
  stage: docker-build
  extends: .docker:build-image-from-upstream
  variables:
    UPSTREAM_GIT_URL: 'https://github.com/jpillora/chisel.git'
    UPSTREAM_DOCKERFILE_PATH: '.'
    IMAGE_NAME: 'chisel'
  rules:
    - if: $DOCKERIMAGEUPDATE

docker-chisel-image-push:
  stage: docker-push
  extends: .docker:push-image-to-registry
  variables:
    UPSTREAM_GIT_URL: 'https://github.com/jpillora/chisel.git'
    UPSTREAM_DOCKERFILE_PATH: '.'
    IMAGE_NAME: 'chisel'
  rules:
    - if: $DOCKERIMAGEUPDATE

docker-syncoid-server-image-get-version:
  stage: docker-get-version
  extends: .docker:get-version
  image: bash:latest
  variables:
    DOCKERFILE_PATH: 'pull-server'
    DOCKERFILE_NAME: 'Dockerfile.syncoid-pull-server'
    IMAGE_NAME: 'syncoid-pull-server'
    #TODO: Tags/versions should track the upstream gitlab-runner image
  rules:
    - if: $DOCKERIMAGEUPDATE
  script:
    - |
      IMAGE_NAME="${IMAGE_NAME:-$(basename "${CI_REGISTRY_IMAGE}")}"
      echo "VERSION_TAGS[latest]=jammy" | tee -a ${IMAGE_NAME}-VERSION_TAGS

docker-syncoid-server-image-build:
  stage: docker-build
  extends: .docker:build-image-from-dockerfile
  variables:
    DOCKERFILE_PATH: 'pull-server'
    DOCKERFILE_NAME: 'Dockerfile.syncoid-pull-server'
    IMAGE_NAME: 'syncoid-pull-server'
  rules:
    - if: $DOCKERIMAGEUPDATE

docker-syncoid-server-image-push:
  stage: docker-push
  extends: .docker:push-image-to-registry
  variables:
    DOCKERFILE_PATH: 'pull-server'
    DOCKERFILE_NAME: 'Dockerfile.syncoid-pull-server'
    IMAGE_NAME: 'syncoid-pull-server'
  rules:
    - if: $DOCKERIMAGEUPDATE

docker-sanoid-client-image-get-version:
  stage: docker-get-version
  extends: .docker:get-version
  image: bash:latest
  variables:
    DOCKERFILE_PATH: 'pull-client'
    DOCKERFILE_NAME: 'Dockerfile.syncoid-pull-client'
    IMAGE_NAME: 'syncoid-pull-client'
  rules:
    - if: $DOCKERIMAGEUPDATE
  script:
    - |
      IMAGE_NAME="${IMAGE_NAME:-$(basename "${CI_REGISTRY_IMAGE}")}"
      echo "VERSION_TAGS[latest]=jammy" | tee -a ${IMAGE_NAME}-VERSION_TAGS

docker-sanoid-client-image-build:
  stage: docker-build
  extends: .docker:build-image-from-dockerfile
  variables:
    DOCKERFILE_PATH: 'pull-client'
    DOCKERFILE_NAME: 'Dockerfile.syncoid-pull-client'
    IMAGE_NAME: 'syncoid-pull-client'
  rules:
    - if: $DOCKERIMAGEUPDATE

docker-sanoid-client-image-push:
  stage: docker-push
  extends: .docker:push-image-to-registry
  variables:
    DOCKERFILE_PATH: 'pull-client'
    DOCKERFILE_NAME: 'Dockerfile.syncoid-pull-client'
    IMAGE_NAME: 'syncoid-pull-client'
  rules:
    - if: $DOCKERIMAGEUPDATE

.run-backups:
  tags:
    TODO
  image: cr.ghanima.net/applications/sanoid-helper-scripts/syncoid-pull:latest
  script: |
    echo "Hi"
    exit 0
